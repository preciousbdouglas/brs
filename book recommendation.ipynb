{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCeYA79m1DEX"
   },
   "source": [
    "Real-world recommender systems typically consist of two distinct stages:\n",
    "\n",
    "1. **Retrieval Stage:**\n",
    "   The primary role of the retrieval stage is to efficiently select an initial set of hundreds of candidates from a vast pool of possibilities. Its fundamental objective is to swiftly eliminate candidates that are unlikely to interest the user. Given the potential involvement with millions of candidates, the retrieval model must prioritize computational efficiency.\n",
    "\n",
    "2. **Ranking Stage:**\n",
    "   Following the retrieval stage, the ranking stage refines the outputs from the retrieval model to pinpoint the best possible recommendations. This stage is dedicated to narrowing down the set of items the user might find interesting, presenting a concise list of highly probable candidates.\n",
    "\n",
    "Retrieval models often consist of two integral sub-models:\n",
    "\n",
    "1. **Query Model:**\n",
    "   Responsible for computing the query representation, usually manifested as a fixed-dimensionality embedding vector, utilizing relevant query features.\n",
    "\n",
    "2. **Candidate Model:**\n",
    "   Tasked with computing the candidate representation, also in the form of an equally-sized vector, using the respective candidate features.\n",
    "\n",
    "The results generated by these two models are then combined by multiplying them, producing a query-candidate affinity score. Higher scores indicate a stronger match between the candidate and the query, aiding in the selection of more personalized and relevant recommendations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sawo1x8kQk9b"
   },
   "source": [
    "## Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "0vJOdh9WbTpd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/scann/\n",
      "ERROR: Could not find a version that satisfies the requirement scann (from versions: none)\n",
      "ERROR: No matching distribution found for scann\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow_datasets==4.9.2 --upgrade\n",
    "# !pip install --force-reinstall -v protobuf==3.20.3\n",
    "# !pip install pandas numpy tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_s</th>\n",
       "      <th>img_m</th>\n",
       "      <th>img_l</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Language</th>\n",
       "      <th>Category</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>0</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Social Science']</td>\n",
       "      <td>stockton</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>5</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11400</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>ottawa</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41385</td>\n",
       "      <td>sudbury, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>sudbury</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id                   location      age        isbn  \\\n",
       "0           0        2  stockton, california, usa  18.0000  0195153448   \n",
       "1           1        8   timmins, ontario, canada  34.7439  0002005018   \n",
       "2           2    11400    ottawa, ontario, canada  49.0000  0002005018   \n",
       "3           3    11676              n/a, n/a, n/a  34.7439  0002005018   \n",
       "4           4    41385   sudbury, ontario, canada  34.7439  0002005018   \n",
       "\n",
       "   rating           book_title           book_author  year_of_publication  \\\n",
       "0       0  Classical Mythology    Mark P. O. Morford               2002.0   \n",
       "1       5         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "2       0         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "3       8         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "4       0         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "\n",
       "                 publisher                                              img_s  \\\n",
       "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                               img_m  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                               img_l  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                             Summary Language  \\\n",
       "0  Provides an introduction to classical myths pl...       en   \n",
       "1  In a small town in Canada, Clara Callan reluct...       en   \n",
       "2  In a small town in Canada, Clara Callan reluct...       en   \n",
       "3  In a small town in Canada, Clara Callan reluct...       en   \n",
       "4  In a small town in Canada, Clara Callan reluct...       en   \n",
       "\n",
       "             Category      city       state country  \n",
       "0  ['Social Science']  stockton  california     usa  \n",
       "1       ['Actresses']   timmins     ontario  canada  \n",
       "2       ['Actresses']    ottawa     ontario  canada  \n",
       "3       ['Actresses']       NaN         NaN     NaN  \n",
       "4       ['Actresses']   sudbury     ontario  canada  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Preprocessed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df[[\"user_id\", \"book_title\"]].astype({\"user_id\": np.str_, \"book_title\": np.str_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(filtered_data['user_id'], tf.string), \\\n",
    "                                                      tf.cast(filtered_data['book_title'], tf.string)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep only the user_id and book_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "uhbEvPJqxLec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': b'2', 'book_title': b'Classical Mythology'}\n",
      "{'user_id': b'8', 'book_title': b'Clara Callan'}\n",
      "{'user_id': b'11400', 'book_title': b'Clara Callan'}\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings_dataset.map(lambda x0, x1: {\n",
    "    \"user_id\": x0,\n",
    "    \"book_title\": x1,\n",
    "})\n",
    "\n",
    "books = ratings_dataset.map(lambda x, x1:x1)\n",
    "\n",
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu4XSa_G1nyN"
   },
   "source": [
    "To facilitate model fitting and evaluation, it is essential to partition the dataset into distinct training and evaluation sets. In a real-world recommender system, this segregation is commonly based on time, where data up to a specific time point \\(T\\) is utilized for predicting interactions occurring after \\(T\\).\n",
    "\n",
    "In this straightforward illustration, however, we will employ a random split, allocating 80% of the ratings to the training set and the remaining 20% to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVi1HJfR9D7H"
   },
   "source": [
    "\"Let's also identify unique user IDs and book titles present in the data. This is important because we need to be able to map the raw values of our categorical features to embedding vectors in our models. To do that, we need a vocabulary that maps a raw feature value to an integer in a contiguous range. This allows us to look up the corresponding embeddings in our embedding tables.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "MKROCiPo_5LJ",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b' A Light in the Storm: The Civil War Diary of Amelia Martin, Fenwick Island, Delaware, 1861 (Dear America)',\n",
       "       b' Always Have Popsicles',\n",
       "       b\" Apple Magic (The Collector's series)\",\n",
       "       b' Ask Lily (Young Women of Faith: Lily Series, Book 5)',\n",
       "       b' Beyond IBM: Leadership Marketing and Finance for the 1990s',\n",
       "       b' Clifford Visita El Hospital (Clifford El Gran Perro Colorado)',\n",
       "       b' Dark Justice', b' Deceived',\n",
       "       b' Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth',\n",
       "       b' Final Fantasy Anthology: Official Strategy Guide (Brady Games)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_titles = books.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "unique_book_titles = np.unique(np.concatenate(list(book_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_book_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## Implementing a model\n",
    "\n",
    "Selecting the architecture for our model is a critical aspect of the modeling process.\n",
    "\n",
    "Given that we are constructing a two-tower retrieval model, we have the flexibility to build each tower independently and subsequently integrate them into the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z20PyfSXP3Um"
   },
   "source": [
    "### The query tower\n",
    "We'll begin by establishing the query tower.\n",
    "\n",
    "The initial step involves determining the dimensionality of the query and candidate representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "QbIy1FP8aCTq"
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJYwjpLRaEzj"
   },
   "source": [
    "Choosing higher values for the dimensionality may lead to models that are potentially more accurate, but they might also require more time for fitting and could be more susceptible to overfitting.\n",
    "\n",
    "The next step is to define the model. In this context, we will utilize Keras preprocessing layers. Initially, we'll convert user IDs to integers and then transform them into user embeddings using an `Embedding` layer. It's noteworthy that we employ the list of unique user IDs obtained earlier as a vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "kHQZJEhXP93N"
   },
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG4YFy9SQ08d"
   },
   "source": [
    "### The candidate tower\n",
    "\n",
    "We can do the same with the candidate tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "qNUwfIJTQ332"
   },
   "outputs": [],
   "source": [
    "book_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r10RiPtqVIAl"
   },
   "source": [
    "### Metrics\n",
    "\n",
    "Within our training data, we possess positive (user, book) pairs. Evaluating our model's performance entails comparing the affinity score calculated by the model for this pair against the scores for all other potential candidates. If the score for the positive pair surpasses that of all other candidates, our model is deemed highly accurate.\n",
    "\n",
    "To facilitate this evaluation, we can employ the `tfrs.metrics.FactorizedTopK` metric. This metric necessitates one essential argument: the dataset of candidates employed as implicit negatives for evaluation.\n",
    "\n",
    "In our scenario, this corresponds to the `books` dataset, transformed into embeddings via our book model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1dLDL6pZVPO8"
   },
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=books.batch(128).map(book_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaCqJsXSkCo"
   },
   "source": [
    "### Loss\n",
    "\n",
    "The subsequent component is the loss employed for training our model. TFRS provides various loss layers and tasks to simplify this process.\n",
    "\n",
    "In this case, we will utilize the `Retrieval` task objectâ€”a convenient wrapper that combines the loss function and metric computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "tJ61Iz2QTBw3"
   },
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-3xFC-1cbz0"
   },
   "source": [
    "The task itself serves as a Keras layer, accepting the query and candidate embeddings as arguments and producing the computed loss. We'll leverage this task layer to implement the training loop for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZUFeSlWRHGx"
   },
   "source": [
    "### The full model\n",
    "\n",
    "We can now integrate all the components into a model. TFRS provides a base model class (`tfrs.models.Model`) that simplifies the model-building process: we just need to configure the components in the `__init__` method and implement the `compute_loss` method, which takes in the raw features and returns a loss value.\n",
    "\n",
    "The base model will handle the creation of the appropriate training loop to fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "8n7c5CHFp0ow"
   },
   "outputs": [],
   "source": [
    "class BookModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, book_model):\n",
    "        super().__init__()\n",
    "        self.book_model: tf.keras.Model = book_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_book_embeddings = self.book_model(features[\"book_title\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_book_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7B8PdfNqyuN"
   },
   "source": [
    "The `tfrs.Model` base class is a simply convenience class: it allows us to compute both training and test losses using the same method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDN_LJGlnRGo"
   },
   "source": [
    "## Fitting and evaluating\n",
    "\n",
    "After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n",
    "\n",
    "Let's first instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "aW63YaqP2wCf"
   },
   "outputs": [],
   "source": [
    "model = BookModel(user_model, book_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nma0vc2XdN5g"
   },
   "source": [
    "Then shuffle, batch, and cache the training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "53QJwY1gUnfv"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8mHTxKAdTJO"
   },
   "source": [
    "Then train the  model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "ZxPntlT8EFOZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 1778s 176s/step - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_100_categorical_accuracy: 2.0000e-04 - loss: 70356.5618 - regularization_loss: 0.0000e+00 - total_loss: 70356.5618\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 1780s 178s/step - factorized_top_k/top_1_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_10_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_50_categorical_accuracy: 8.6250e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0019 - loss: 69249.7330 - regularization_loss: 0.0000e+00 - total_loss: 69249.7330\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 1751s 174s/step - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0030 - factorized_top_k/top_10_categorical_accuracy: 0.0030 - factorized_top_k/top_50_categorical_accuracy: 0.0057 - factorized_top_k/top_100_categorical_accuracy: 0.0188 - loss: 65724.4645 - regularization_loss: 0.0000e+00 - total_loss: 65724.4645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e0c98dae90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gxp5RLFcv64"
   },
   "source": [
    "Finally, we can evaluate our model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-zu6HLODNeI"
   },
   "outputs": [],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKZyP9A1dxit"
   },
   "source": [
    "The disparity in performance between the test set and training set can be attributed to two key factors:\n",
    "\n",
    "1. **Overfitting:** The model is likely to exhibit better performance on data it has encountered during training, essentially memorizing it. This overfitting tendency is more pronounced in models with numerous parameters. Techniques such as model regularization and the incorporation of user and movie features can mitigate this effect, promoting better generalization to unseen data.\n",
    "\n",
    "\n",
    "2. **Recommending Previously Watched Movies:** The model may re-recommend movies that users have already watched. This situation can overshadow test movies in the top K recommendations. While it's a common practice in recommender systems to exclude past watches from test recommendations, we don't adopt this approach in these tutorials. If avoiding recommendations of past watches is crucial, appropriately configured models should learn this behavior autonomously from user history and contextual information. Furthermore, recommending the same item multiple times, such as evergreen TV series or regularly purchased items, is often considered appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB2v43NJU3Xf"
   },
   "source": [
    "## Making predictions\n",
    "\n",
    "Now that we have a model, we would like to be able to make predictions. We can use the `tfrs.layers.factorized_top_k.BruteForce` layer to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "IRD6bEtZW_8j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 8: [b'Angels & Demons'\n",
      " b'Cruel & Unusual (Kay Scarpetta Mysteries (Paperback))'\n",
      " b'Harry Potter and the Chamber of Secrets (Book 2)' b'Dead Aim'\n",
      " b'The Lake House' b'Jack & Jill (Alex Cross Novels)' b'Toxin'\n",
      " b'Along Came a Spider (Alex Cross Novels)' b'When the Wind Blows'\n",
      " b'Icebound']\n"
     ]
    }
   ],
   "source": [
    "# get unique set of books\n",
    "batched_unique_books = tf.data.Dataset.from_tensor_slices(unique_book_titles)\n",
    "\n",
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((batched_unique_books.batch(100), batched_unique_books.batch(100).map(model.book_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"10\"]))\n",
    "print(f\"Recommendations for user 8: {titles[0, :10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "oJkRNBfCW5_E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.21195796>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the query model.\n",
    "path = \"saved_index\"\n",
    "tf.saved_model.save(index, path)\n",
    "\n",
    "# Load it back;\n",
    "loaded = tf.saved_model.load(path)\n",
    "\n",
    "# Pass a user id in, get top predicted book titles back.\n",
    "scores, titles = loaded([\"100\"])\n",
    "\n",
    "for x in titles[0][:3]:\n",
    "    title_string = x.numpy().decode(\"utf-8\")\n",
    "    print(f\"Recommended Book: {title_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "basic_retrieval.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

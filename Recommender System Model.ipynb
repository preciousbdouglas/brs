{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ead15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import pickle\n",
    "from typing import Dict, Text\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras.layers import Embedding, Concatenate, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2104fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_s</th>\n",
       "      <th>img_m</th>\n",
       "      <th>img_l</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Language</th>\n",
       "      <th>Category</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>0</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Social Science']</td>\n",
       "      <td>stockton</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>5</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11400</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>ottawa</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41385</td>\n",
       "      <td>sudbury, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>sudbury</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id                   location      age        isbn  \\\n",
       "0           0        2  stockton, california, usa  18.0000  0195153448   \n",
       "1           1        8   timmins, ontario, canada  34.7439  0002005018   \n",
       "2           2    11400    ottawa, ontario, canada  49.0000  0002005018   \n",
       "3           3    11676              n/a, n/a, n/a  34.7439  0002005018   \n",
       "4           4    41385   sudbury, ontario, canada  34.7439  0002005018   \n",
       "\n",
       "   rating           book_title           book_author  year_of_publication  \\\n",
       "0       0  Classical Mythology    Mark P. O. Morford               2002.0   \n",
       "1       5         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "2       0         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "3       8         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "4       0         Clara Callan  Richard Bruce Wright               2001.0   \n",
       "\n",
       "                 publisher                                              img_s  \\\n",
       "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                               img_m  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                               img_l  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                             Summary Language  \\\n",
       "0  Provides an introduction to classical myths pl...       en   \n",
       "1  In a small town in Canada, Clara Callan reluct...       en   \n",
       "2  In a small town in Canada, Clara Callan reluct...       en   \n",
       "3  In a small town in Canada, Clara Callan reluct...       en   \n",
       "4  In a small town in Canada, Clara Callan reluct...       en   \n",
       "\n",
       "             Category      city       state country  \n",
       "0  ['Social Science']  stockton  california     usa  \n",
       "1       ['Actresses']   timmins     ontario  canada  \n",
       "2       ['Actresses']    ottawa     ontario  canada  \n",
       "3       ['Actresses']       NaN         NaN     NaN  \n",
       "4       ['Actresses']   sudbury     ontario  canada  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv to memory\n",
    "df = pd.read_csv(\"Preprocessed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3c1b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1031175 entries, 0 to 1031174\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   user_id              1031175 non-null  int64  \n",
      " 1   location             1031175 non-null  object \n",
      " 2   age                  1031175 non-null  float64\n",
      " 3   isbn                 1031175 non-null  object \n",
      " 4   rating               1031175 non-null  int64  \n",
      " 5   book_title           1031175 non-null  object \n",
      " 6   book_author          1031175 non-null  object \n",
      " 7   year_of_publication  1031175 non-null  float64\n",
      " 8   publisher            1031175 non-null  object \n",
      " 9   img_s                1031175 non-null  object \n",
      " 10  img_m                1031175 non-null  object \n",
      " 11  img_l                1031175 non-null  object \n",
      " 12  Summary              1031175 non-null  object \n",
      " 13  Language             1031175 non-null  object \n",
      " 14  Category             1031175 non-null  object \n",
      " 15  city                 1017072 non-null  object \n",
      " 16  state                1008377 non-null  object \n",
      " 17  country              995801 non-null   object \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 141.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1031175, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'Unnamed' column\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head()\n",
    "\n",
    "# view information about the dataset\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0896021",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43222838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the required column for the model and web app\n",
    "cleaned_data = df[[\"user_id\", \"book_title\", \"rating\", \"img_l\", \"book_author\"]]\n",
    "\n",
    "# save the new dataset to memory\n",
    "cleaned_data.to_csv(\"filtered_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fd4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datatypes to TensorFlow datatypes\n",
    "cleaned_data = df[[\"user_id\", \"book_title\", \"rating\", \"book_author\"]].astype({\"user_id\": np.str_, \n",
    "                                                                               \"book_title\": np.str_, \n",
    "                                                                               \"rating\": np.float32, \n",
    "                                                                               \"book_author\": np.str_}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ea8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tf.data.Dataset API allows for writing descriptive and efficient input pipelines.\n",
    "ratings_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(cleaned_data['user_id'], tf.string),\n",
    "                                                      tf.cast(cleaned_data['book_title'], tf.string),\n",
    "                                                      tf.cast(cleaned_data['rating'], tf.float32),\n",
    "                                                      tf.cast(cleaned_data['book_author'], tf.string)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abfccb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "{'book_author': b'Mark P. O. Morford',\n",
      " 'book_title': b'Classical Mythology',\n",
      " 'rating': 0.0,\n",
      " 'user_id': b'2'}\n"
     ]
    }
   ],
   "source": [
    "# assign names to the TensorFlow datatypes\n",
    "ratings = ratings_dataset.map(lambda x0, x1, x2, x3: {\n",
    "    \"user_id\": x0,\n",
    "    \"book_title\": x1,\n",
    "    \"rating\": x2,\n",
    "    \"book_author\": x3\n",
    "})\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b22597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset for training and testing\n",
    "tf.random.set_seed(1990)\n",
    "shuffled = ratings.shuffle(100_000, seed=1990, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(75_000)\n",
    "test = shuffled.skip(75_000).take(25_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c1c4d",
   "metadata": {},
   "source": [
    "### Getting the Unique Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba32e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique data \n",
    "book_titles = ratings.batch(1_000_000).map(lambda x: x[\"book_title\"])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_book_titles = np.unique(np.concatenate(list(book_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863b90e",
   "metadata": {},
   "source": [
    "### Saving the unique IDs and Book Titles for App Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b34253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unique data to memory\n",
    "with open(\"unique_book_titles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(unique_book_titles, f)\n",
    "    \n",
    "with open(\"unique_user_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(unique_user_ids, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7ac52",
   "metadata": {},
   "source": [
    "### Two Tower Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77249bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Model Architechture\n",
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for books.\n",
    "        self.books_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_book_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_book_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, book_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        book_embedding = self.books_embeddings(book_title)\n",
    "        \n",
    "        return self.ratings(tf.concat([user_embedding, book_embedding], axis=1))\n",
    "\n",
    "    \n",
    "\n",
    "# Reference https://www.tensorflow.org/recommenders/examples/basic_ranking\n",
    "# Reference https://medium.com/@hamza.emra/introduction-to-recommendation-systems-with-tensorflow-recommenders-a116e5e5a940\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977614a",
   "metadata": {},
   "source": [
    "### Model Loss and Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13e06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the loss function metric computation\n",
    "task = tfrs.tasks.Ranking(\n",
    "  loss = tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68888d1a",
   "metadata": {},
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1de50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TensorFlow libraries to build model\n",
    "class BookModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "        return self.ranking_model(\n",
    "        (features[\"user_id\"], features[\"book_title\"]))\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        labels = features.pop(\"rating\")\n",
    "    \n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fba618",
   "metadata": {},
   "source": [
    "### Model Training and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f66b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "293/293 [==============================] - 8s 9ms/step - root_mean_squared_error: 3.8124 - loss: 14.5309 - regularization_loss: 0.0000e+00 - total_loss: 14.5309 - val_root_mean_squared_error: 3.6928 - val_loss: 13.4828 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13.4828\n",
      "Epoch 2/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 3.3657 - loss: 11.3263 - regularization_loss: 0.0000e+00 - total_loss: 11.3263 - val_root_mean_squared_error: 3.8800 - val_loss: 14.4571 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14.4571\n",
      "Epoch 3/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.9417 - loss: 8.6518 - regularization_loss: 0.0000e+00 - total_loss: 8.6518 - val_root_mean_squared_error: 3.9550 - val_loss: 14.6301 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14.6301\n",
      "Epoch 4/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.5763 - loss: 6.6366 - regularization_loss: 0.0000e+00 - total_loss: 6.6366 - val_root_mean_squared_error: 3.9874 - val_loss: 14.6530 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14.6530\n",
      "Epoch 5/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.3592 - loss: 5.5663 - regularization_loss: 0.0000e+00 - total_loss: 5.5663 - val_root_mean_squared_error: 4.1721 - val_loss: 16.0297 - val_regularization_loss: 0.0000e+00 - val_total_loss: 16.0297\n",
      "Epoch 6/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.2446 - loss: 5.0376 - regularization_loss: 0.0000e+00 - total_loss: 5.0376 - val_root_mean_squared_error: 4.2060 - val_loss: 16.5456 - val_regularization_loss: 0.0000e+00 - val_total_loss: 16.5456\n",
      "Epoch 7/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.1388 - loss: 4.5744 - regularization_loss: 0.0000e+00 - total_loss: 4.5744 - val_root_mean_squared_error: 4.2620 - val_loss: 16.6529 - val_regularization_loss: 0.0000e+00 - val_total_loss: 16.6529\n",
      "Epoch 8/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.0771 - loss: 4.3135 - regularization_loss: 0.0000e+00 - total_loss: 4.3135 - val_root_mean_squared_error: 4.3343 - val_loss: 17.6246 - val_regularization_loss: 0.0000e+00 - val_total_loss: 17.6246\n",
      "Epoch 9/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 2.0215 - loss: 4.0870 - regularization_loss: 0.0000e+00 - total_loss: 4.0870 - val_root_mean_squared_error: 4.4029 - val_loss: 18.1547 - val_regularization_loss: 0.0000e+00 - val_total_loss: 18.1547\n",
      "Epoch 10/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.9703 - loss: 3.8828 - regularization_loss: 0.0000e+00 - total_loss: 3.8828 - val_root_mean_squared_error: 4.3778 - val_loss: 18.3980 - val_regularization_loss: 0.0000e+00 - val_total_loss: 18.3980\n",
      "Epoch 11/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.9177 - loss: 3.6777 - regularization_loss: 0.0000e+00 - total_loss: 3.6777 - val_root_mean_squared_error: 4.4590 - val_loss: 18.6114 - val_regularization_loss: 0.0000e+00 - val_total_loss: 18.6114\n",
      "Epoch 12/25\n",
      "293/293 [==============================] - 1s 5ms/step - root_mean_squared_error: 1.8777 - loss: 3.5267 - regularization_loss: 0.0000e+00 - total_loss: 3.5267 - val_root_mean_squared_error: 4.4349 - val_loss: 19.4159 - val_regularization_loss: 0.0000e+00 - val_total_loss: 19.4159\n",
      "Epoch 13/25\n",
      "293/293 [==============================] - 1s 5ms/step - root_mean_squared_error: 1.8484 - loss: 3.4169 - regularization_loss: 0.0000e+00 - total_loss: 3.4169 - val_root_mean_squared_error: 4.5247 - val_loss: 20.2259 - val_regularization_loss: 0.0000e+00 - val_total_loss: 20.2259\n",
      "Epoch 14/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.8029 - loss: 3.2516 - regularization_loss: 0.0000e+00 - total_loss: 3.2516 - val_root_mean_squared_error: 4.5398 - val_loss: 20.8827 - val_regularization_loss: 0.0000e+00 - val_total_loss: 20.8827\n",
      "Epoch 15/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.7631 - loss: 3.1092 - regularization_loss: 0.0000e+00 - total_loss: 3.1092 - val_root_mean_squared_error: 4.5520 - val_loss: 21.3408 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21.3408\n",
      "Epoch 16/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.7374 - loss: 3.0190 - regularization_loss: 0.0000e+00 - total_loss: 3.0190 - val_root_mean_squared_error: 4.5683 - val_loss: 21.5187 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21.5187\n",
      "Epoch 17/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.7148 - loss: 2.9414 - regularization_loss: 0.0000e+00 - total_loss: 2.9414 - val_root_mean_squared_error: 4.5912 - val_loss: 21.6060 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21.6060\n",
      "Epoch 18/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.6686 - loss: 2.7846 - regularization_loss: 0.0000e+00 - total_loss: 2.7846 - val_root_mean_squared_error: 4.6271 - val_loss: 22.3504 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22.3504\n",
      "Epoch 19/25\n",
      "293/293 [==============================] - 2s 6ms/step - root_mean_squared_error: 1.6212 - loss: 2.6292 - regularization_loss: 0.0000e+00 - total_loss: 2.6292 - val_root_mean_squared_error: 4.6484 - val_loss: 22.9217 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22.9217\n",
      "Epoch 20/25\n",
      "293/293 [==============================] - 1s 5ms/step - root_mean_squared_error: 1.5872 - loss: 2.5201 - regularization_loss: 0.0000e+00 - total_loss: 2.5201 - val_root_mean_squared_error: 4.6607 - val_loss: 23.1755 - val_regularization_loss: 0.0000e+00 - val_total_loss: 23.1755\n",
      "Epoch 21/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.5525 - loss: 2.4109 - regularization_loss: 0.0000e+00 - total_loss: 2.4109 - val_root_mean_squared_error: 4.6662 - val_loss: 23.9014 - val_regularization_loss: 0.0000e+00 - val_total_loss: 23.9014\n",
      "Epoch 22/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.5257 - loss: 2.3286 - regularization_loss: 0.0000e+00 - total_loss: 2.3286 - val_root_mean_squared_error: 4.7052 - val_loss: 24.2189 - val_regularization_loss: 0.0000e+00 - val_total_loss: 24.2189\n",
      "Epoch 23/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.4939 - loss: 2.2327 - regularization_loss: 0.0000e+00 - total_loss: 2.2327 - val_root_mean_squared_error: 4.6858 - val_loss: 24.8417 - val_regularization_loss: 0.0000e+00 - val_total_loss: 24.8417\n",
      "Epoch 24/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.4583 - loss: 2.1277 - regularization_loss: 0.0000e+00 - total_loss: 2.1277 - val_root_mean_squared_error: 4.7079 - val_loss: 24.3401 - val_regularization_loss: 0.0000e+00 - val_total_loss: 24.3401\n",
      "Epoch 25/25\n",
      "293/293 [==============================] - 1s 4ms/step - root_mean_squared_error: 1.4234 - loss: 2.0268 - regularization_loss: 0.0000e+00 - total_loss: 2.0268 - val_root_mean_squared_error: 4.6945 - val_loss: 24.6729 - val_regularization_loss: 0.0000e+00 - val_total_loss: 24.6729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2172f11c8e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting and training\n",
    "model = BookModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "train_data = train.shuffle(len(train)).batch(256).cache().take(100_000)\n",
    "test_data = test.batch(256).cache()\n",
    "\n",
    "model.fit(train_data, epochs=25, validation_data=test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83d713",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc844e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - root_mean_squared_error: 4.6945 - loss: 22.0736 - regularization_loss: 0.0000e+00 - total_loss: 22.0736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 4.694451332092285,\n",
       " 'loss': 24.672855377197266,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 24.672855377197266}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.evaluate(test_data, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8e37a",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b1c761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Light in the Storm: The Civil War Diary of Amelia Martin, Fenwick Island, Delaware, 1861 (Dear America): [[5.160743]]\n",
      " Beyond IBM: Leadership Marketing and Finance for the 1990s: [[5.123688]]\n",
      " Apple Magic (The Collector's series): [[4.7389765]]\n",
      " Deceived: [[4.6452193]]\n",
      " Goosebumps Monster Edition 1: Welcome to Dead House, Stay Out of the Basement, and Say Cheese and Die!: [[4.520405]]\n",
      " Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth: [[4.3941865]]\n",
      " Dark Justice: [[4.1910596]]\n",
      " Garfield Bigger and Better (Garfield (Numbered Paperback)): [[4.0861483]]\n",
      " Always Have Popsicles: [[3.9559033]]\n",
      " Flight of Fancy: American Heiresses (Zebra Ballad Romance): [[3.9290657]]\n",
      " Ask Lily (Young Women of Faith: Lily Series, Book 5): [[3.867418]]\n",
      " Final Fantasy Anthology: Official Strategy Guide (Brady Games): [[3.8005188]]\n",
      " Good Wives: Image and Reality in the Lives of Women in Northern New England, 1650-1750: [[3.4033701]]\n",
      " Clifford Visita El Hospital (Clifford El Gran Perro Colorado): [[3.1609285]]\n",
      " God's Little Promise Book: [[3.0423372]]\n"
     ]
    }
   ],
   "source": [
    "# model testing\n",
    "test_ratings = {}\n",
    "for book_title in unique_book_titles[:15]:\n",
    "      test_ratings[book_title.decode(\"utf-8\")] = model({\n",
    "      \"user_id\": np.array([\"15\"]),\n",
    "      \"book_title\": np.array([book_title])\n",
    "  })\n",
    "\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c0000",
   "metadata": {},
   "source": [
    "### Save Model for App Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d31418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as ranking_1_layer_call_fn, ranking_1_layer_call_and_return_conditional_losses, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[5.6822557]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "tf.saved_model.save(model, \"saved_index\")\n",
    "\n",
    "#loading the model to confirm functionality\n",
    "loaded = tf.saved_model.load(\"saved_index\")\n",
    "\n",
    "loaded({\"user_id\": np.array([\"15\"]), \n",
    "        \"book_title\":np.array([\"Dark Justice\"]), \n",
    "        \"book_author\":np.array([\"Richard Bruce Wright\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e7598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc158c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b1fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb733ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd664e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bdeed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89ff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e22ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd26da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf9228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c361a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac204d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a35e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c12b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3940b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0966fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cf6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e0c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875efb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46e43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b56a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bac1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1bbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9ec7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b018913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d2c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ad29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348972ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8d986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b5756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643099e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04159717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a548b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e000f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753713bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd34d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6466a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1ff09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba806dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11196aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbfdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd2c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455034eb",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d621972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cosine similarity\n",
    "filtered_data = pd.read_csv('filtered_df.csv')\n",
    "df = filtered_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18811a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify users with more than 200 ratings\n",
    "x = df.groupby('user_id').count()['rating'] > 200\n",
    "similar_users = x[x].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34696209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter ratings data to include only ratings from similar users\n",
    "filtered_rating = df[df['user_id'].isin(similar_users)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab3b6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Identify books with 50 or more ratings\n",
    "y = filtered_rating.groupby('book_title').count()['rating'] >= 50\n",
    "famous_books = y[y].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cd6e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Filter ratings data to include only ratings for famous books\n",
    "final_ratings = filtered_rating[filtered_rating['book_title'].isin(famous_books)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a90892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id              254     2276    2766    2977    3363    4017    4385    \\\n",
      "book_title                                                                    \n",
      "1984                    9.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1st to Die: A Novel     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2nd Chance              0.0    10.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4 Blondes               0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "A Bend in the Road      0.0     0.0     7.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "user_id              6251    6323    6543    ...  271705  273979  274004  \\\n",
      "book_title                                   ...                           \n",
      "1984                    0.0     0.0     0.0  ...    10.0     0.0     0.0   \n",
      "1st to Die: A Novel     0.0     0.0     9.0  ...     0.0     0.0     0.0   \n",
      "2nd Chance              0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "4 Blondes               0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "A Bend in the Road      0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "\n",
      "user_id              274061  274301  274308  275970  277427  277639  278418  \n",
      "book_title                                                                   \n",
      "1984                    0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "1st to Die: A Novel     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2nd Chance              0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "4 Blondes               0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "A Bend in the Road      0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 810 columns]\n"
     ]
    }
   ],
   "source": [
    "#table\n",
    "pt = final_ratings.pivot_table(index='book_title', columns='user_id', values='rating')\n",
    "\n",
    "pt.fillna(0,inplace=True)\n",
    "print(pt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cad53f",
   "metadata": {},
   "source": [
    "### Calculating the Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4ff12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harry Potter and the Sorcerer's Stone (Book 1) by J. K. Rowling\",\n",
       " 'Year of Wonders by Geraldine Brooks',\n",
       " 'Harry Potter and the Chamber of Secrets (Book 2) by J. K. Rowling',\n",
       " 'Dragonfly in Amber by DIANA GABALDON',\n",
       " 'Harry Potter and the Order of the Phoenix (Book 5) by J. K. Rowling',\n",
       " 'The Valley of Horses by JEAN M. AUEL',\n",
       " 'The Hundred Secret Senses by Amy Tan']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate similarity scores using cosine similarity\n",
    "similarity_scores = cosine_similarity(pt)\n",
    "\n",
    "def recommend(book_title, pt, similarity_scores, df):\n",
    "    \n",
    "    # Find index of the input book\n",
    "    index = np.where(pt.index == book_title)[0][0]\n",
    "\n",
    "    # Sort similar items by similarity score and select top recommendations\n",
    "    similar_items = sorted(\n",
    "        ((i, score) for i, score in enumerate(similarity_scores[index])),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[1:8]  # Only considering the top 7 similar items\n",
    "\n",
    "    # Initialize a list to store recommended books\n",
    "    recommended_books = []\n",
    "\n",
    "    # Loop through the similar items and gather book information for recommendations\n",
    "    for i, _ in similar_items:\n",
    "        # Filter the DataFrame to get information about the recommended book\n",
    "        temp_df = df[df['book_title'] == pt.index[i]]\n",
    "        book_info = temp_df.drop_duplicates('book_title')[['book_title', \"book_author\"]].values[0]\n",
    "        recommended_books.append(f\"{book_info[0]} by {book_info[1]}\")\n",
    "\n",
    "    # Return the list of recommended books\n",
    "    return recommended_books\n",
    "\n",
    "# input the book to recommend\n",
    "recommend(\"The Mists of Avalon\", pt, similarity_scores, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8cbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b3780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147317f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcdc909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba136f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3efac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efae30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a0be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8179afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eccc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87adf577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20aa8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7e310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cc1a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 14:44:17.160 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# from functions import *\n",
    "\n",
    "\n",
    "st.set_page_config(layout=\"centered\")\n",
    "with open(\"style.css\") as f:\n",
    "    st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"ðŸ“šBook Recommendation Web App\")\n",
    "st.markdown(\"#\")\n",
    "st.markdown(\"#\")\n",
    "\n",
    "\n",
    "st.sidebar.markdown(f\" ## :gear: Recommendation Settings\")\n",
    "st.sidebar.markdown(\"---\")\n",
    "no_of_rec = int(st.sidebar.slider(\"Select Number of Book Recommendations\", 1, 50, 10))\n",
    "n_cols = st.sidebar.number_input(\"Select Number of columns\", 5)\n",
    "n_cols = int(n_cols)\n",
    "\n",
    "\n",
    "@st.cache_resource\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"filtered_df.csv\")\n",
    "\n",
    "    book_titles = pickle.load(open(\"unique_book_titles.pkl\", \"rb\"))\n",
    "    user_ids = pickle.load(open(\"unique_user_ids.pkl\", \"rb\"))\n",
    "\n",
    "    decoded_titles = [title.decode(\"utf-8\") for title in book_titles]\n",
    "    decoded_user_ids = [user.decode(\"utf-8\") for user in user_ids]\n",
    "\n",
    "    # Load model\n",
    "    loaded_model = tf.saved_model.load(\"export\")\n",
    "\n",
    "    return decoded_titles, decoded_user_ids, loaded_model, df\n",
    "\n",
    "\n",
    "unique_book_titles, unique_user_ids, rec_model, df = load_data()\n",
    "\n",
    "\n",
    "def recommend_books(user_id, top_k):\n",
    "    recommendations = []\n",
    "    ratings = {}\n",
    "\n",
    "    for book_title in unique_book_titles[:top_k]:\n",
    "        ratings[book_title] = rec_model(\n",
    "            {\"user_id\": np.array([user_id]), \"book_title\": np.array([book_title])}\n",
    "        )\n",
    "\n",
    "    for title, score in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        top_books = {}\n",
    "        top_books[\"title\"] = title\n",
    "        top_books[\"score\"] = f\"{score[0][0]: .2f}\"\n",
    "        recommendations.append(top_books)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def image_cover(df, book_name):\n",
    "    link = df[df[\"book_title\"] == book_name][\"img_l\"].values\n",
    "\n",
    "    if len(link) > 1:\n",
    "        return link[1]\n",
    "    else:\n",
    "        return link[0]\n",
    "\n",
    "\n",
    "def get_user(df, id):\n",
    "    # books = \"\"\n",
    "    user_data = df[df[\"user_id\"] == id][:5]\n",
    "    books = user_data[\"book_title\"].values\n",
    "    rating = user_data[\"rating\"].values\n",
    "    authors = user_data[\"book_author\"].values\n",
    "\n",
    "    return books, rating, authors\n",
    "\n",
    "\n",
    "user_id = st.selectbox(\"Select a user\", unique_user_ids)\n",
    "rec_btn = st.button(\"Recommend Books\")\n",
    "st.markdown(\"#\")\n",
    "st.markdown(\"#\")\n",
    "\n",
    "\n",
    "plc_holder = st.container()\n",
    "\n",
    "\n",
    "if rec_btn:\n",
    "    with plc_holder:\n",
    "        st.markdown(f\"#### These are some of the books user {user_id} has read\")\n",
    "        st.markdown(\"---\")\n",
    "        books, ratings, authors = get_user(df, int(user_id))\n",
    "\n",
    "        n_rows = int(1 + 3 // 3)\n",
    "        rows = [st.columns(n_cols) for _ in range(3)]\n",
    "        cols = [column for row in rows for column in row]\n",
    "\n",
    "        for col, title, rating, author in zip(cols, books, ratings, authors):\n",
    "            col.write(f\" :blue[Title]: {title[:15]}...\")\n",
    "            col.write(f\" :blue[Rating]: {rating}\")\n",
    "            col.write(f\" :blue[Author]: {author}\")\n",
    "            col.image(image_cover(df, title))\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # RECOMMENDATION SIDE\n",
    "    st.subheader(f\"Top {no_of_rec} Ranked Book Recommendations for user {user_id}\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    top_rec = recommend_books(user_id, no_of_rec)\n",
    "\n",
    "    covers = []\n",
    "    titles = []\n",
    "    scores = []\n",
    "\n",
    "    for rec in top_rec:\n",
    "        covers.append(image_cover(df, rec[\"title\"]))\n",
    "        titles.append(rec[\"title\"])\n",
    "        scores.append(rec[\"score\"])\n",
    "\n",
    "    n_rows = int(1 + no_of_rec // n_cols)\n",
    "    rows = [st.columns(n_cols) for _ in range(n_cols)]\n",
    "    cols = [column for row in rows for column in row]\n",
    "\n",
    "    for col, poster, title, score in zip(cols, covers, titles, scores):\n",
    "        col.markdown(f\"###### :blue[Title]: {title[:15]}...\")\n",
    "        col.write(f\" :blue[Rank]: {score}\")\n",
    "\n",
    "        col.image(poster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a82b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db12004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f99fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecd528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa32b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe19bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc430f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fed919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb88cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d7d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3139a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e972e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c97e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94da7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0360c207",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [36135 84771  5022 ... 65492 65492 65492]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14928\\3091693554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Create and compile the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoded_user_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_book_titles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_book_authors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean_squared_error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             if not all(\n\u001b[1;32m--> 158\u001b[1;33m                 [\n\u001b[0m\u001b[0;32m    159\u001b[0m                     \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_input_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    157\u001b[0m             if not all(\n\u001b[0;32m    158\u001b[0m                 [\n\u001b[1;32m--> 159\u001b[1;33m                     \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_input_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 ]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional_utils.py\u001b[0m in \u001b[0;36mis_input_keras_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \"\"\"\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [36135 84771  5022 ... 65492 65492 65492]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Concatenate, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create label encoders for categorical features\n",
    "user_encoder = LabelEncoder()\n",
    "user_ids = cleaned_data[\"user_id\"].values\n",
    "encoded_user_ids = user_encoder.fit_transform(user_ids)\n",
    "\n",
    "book_title_encoder = LabelEncoder()\n",
    "book_titles = cleaned_data[\"book_title\"].values\n",
    "encoded_book_titles = book_title_encoder.fit_transform(book_titles)\n",
    "\n",
    "book_author_encoder = LabelEncoder()\n",
    "book_authors = cleaned_data[\"book_author\"].values\n",
    "encoded_book_authors = book_author_encoder.fit_transform(book_authors)\n",
    "\n",
    "# Create embeddings for text features\n",
    "embedding_dim = 50\n",
    "\n",
    "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(encoded_user_ids)\n",
    "book_title_embedding = Embedding(input_dim=len(book_title_encoder.classes_), output_dim=embedding_dim)(encoded_book_titles)\n",
    "book_author_embedding = Embedding(input_dim=len(book_author_encoder.classes_), output_dim=embedding_dim)(encoded_book_authors)\n",
    "\n",
    "# Combine embeddings and other user features\n",
    "user_features = Flatten()(user_embedding)\n",
    "book_features = Concatenate()([book_title_embedding, book_author_embedding])\n",
    "book_features = Flatten()(book_features)\n",
    "\n",
    "# Concatenate user and book features\n",
    "concatenated = Concatenate()([user_features, book_features])\n",
    "\n",
    "# Add dense layers for prediction\n",
    "dense_layer = Dense(64, activation=\"relu\")(concatenated)\n",
    "output = Dense(1)(dense_layer)\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=[encoded_user_ids, encoded_book_titles, encoded_book_authors], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Train the model\n",
    "model.fit([encoded_user_ids, encoded_book_titles, encoded_book_authors], cleaned_data[\"rating\"], epochs=10, batch_size=64)\n",
    "\n",
    "# Make predictions for recommendations\n",
    "user_id_for_recommendation = user_encoder.transform([\"100002\"])\n",
    "all_book_titles = book_title_encoder.classes_\n",
    "all_book_authors = book_author_encoder.classes_\n",
    "\n",
    "predictions = model.predict([\n",
    "    np.array([user_id_for_recommendation] * len(all_book_titles)), \n",
    "    np.arange(len(all_book_titles)), \n",
    "    np.arange(len(all_book_authors))\n",
    "])\n",
    "\n",
    "# Recommend books with highest predicted ratings\n",
    "recommended_books_indices = predictions.argsort()[-10:][::-1]\n",
    "recommended_books = all_book_titles[recommended_books_indices]\n",
    "\n",
    "print(\"Recommended Books:\", recommended_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbd82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
